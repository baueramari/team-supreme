{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a445a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from convokit import Corpus, download\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import gender_guesser.detector as gender\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17df14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: jt\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00428bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = pd.read_csv('data/X_train_all.csv', index_col = 'id')\n",
    "X_test_all = pd.read_csv('data/X_test_all.csv', index_col = 'id')\n",
    "\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d5c00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    507.361732\n",
       "win_side        0.653631\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9f6760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    511.000000\n",
       "win_side        0.652981\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pd.concat([y_train,y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01048a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state = 0)\n",
    "param_space = {'activation' : ['tanh', 'relu'],\n",
    "              'solver': ['sgd', 'adam']}\n",
    "search = GridSearchCV(mlp, param_space, n_jobs=-1, cv=3, return_train_score=True)\n",
    "search.fit(X_train_all, y_train.loc[:,'win_side'])\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results = results.loc[:, ['param_solver', 'param_activation', 'mean_train_score', 'mean_test_score', 'rank_test_score']]\n",
    "results = results.sort_values('rank_test_score')\n",
    "results #SGD looks best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d90241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgd</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sgd</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_solver param_activation  mean_train_score  mean_test_score  \\\n",
       "0          sgd             tanh          0.653632         0.653634   \n",
       "2          sgd             relu          0.653632         0.653634   \n",
       "1         adam             tanh          1.000000         0.607579   \n",
       "3         adam             relu          1.000000         0.606185   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "2                1  \n",
       "1                3  \n",
       "3                4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad5f975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_iter  mean_train_score  mean_test_score  rank_test_score\n",
       "0            500          0.653632         0.653634                1\n",
       "1           1000          0.653632         0.653634                1\n",
       "2           2000          0.653632         0.653634                1\n",
       "3           3000          0.653632         0.653634                1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state = 0, solver = 'sgd')\n",
    "param_space = {'max_iter' : [500, 1000, 2000,3000],}\n",
    "search = GridSearchCV(mlp, param_space, n_jobs=-1, cv=3, return_train_score=True)\n",
    "search.fit(X_train_all, y_train.loc[:,'win_side'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results = results.loc[:, ['param_max_iter', 'mean_train_score', 'mean_test_score', 'rank_test_score']]\n",
    "results = results.sort_values('rank_test_score')\n",
    "results #500 for max_iter is sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486cc7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(100, 50, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(100, 50, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_hidden_layer_sizes param_activation  mean_train_score  \\\n",
       "0            (100, 50, 25)             tanh          0.653632   \n",
       "1                (4, 3, 2)             tanh          0.653632   \n",
       "2             (50, 40, 25)             tanh          0.653632   \n",
       "3            (100, 50, 25)             relu          0.653632   \n",
       "4                (4, 3, 2)             relu          0.653632   \n",
       "5             (50, 40, 25)             relu          0.653632   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "0         0.653634                1  \n",
       "1         0.653634                1  \n",
       "2         0.653634                1  \n",
       "3         0.653634                1  \n",
       "4         0.653634                1  \n",
       "5         0.653634                1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state = 0, solver = 'sgd', max_iter = 500)\n",
    "param_space = {'hidden_layer_sizes': [(100,50,25),(4,3,2), (50,40,25)],\n",
    "              'activation' : ['tanh', 'relu']}\n",
    "search = GridSearchCV(mlp, param_space, n_jobs=-1, cv=3, return_train_score=True)\n",
    "search.fit(X_train_all, y_train.loc[:,'win_side'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results = results.loc[:, ['param_hidden_layer_sizes', 'param_activation', 'mean_train_score', 'mean_test_score', 'rank_test_score']]\n",
    "results = results.sort_values('rank_test_score')\n",
    "results #no distinction with different activations/hidden layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd605ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_alpha param_learning_rate  mean_train_score  mean_test_score  \\\n",
       "0        0.01            constant          0.653632         0.653634   \n",
       "1        0.01            adaptive          0.653632         0.653634   \n",
       "2        0.05            constant          0.653632         0.653634   \n",
       "3        0.05            adaptive          0.653632         0.653634   \n",
       "4         0.1            constant          0.653632         0.653634   \n",
       "5         0.1            adaptive          0.653632         0.653634   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state = 0, max_iter = 500, solver = 'sgd')#do not run again, this will take forever.\n",
    "param_space = {'alpha': [0.0001, 0.01, 0.05, 0.1],\n",
    "    'learning_rate': ['constant','adaptive']}\n",
    "search = GridSearchCV(mlp, param_space, n_jobs=-1, cv=3, return_train_score=True)\n",
    "search.fit(X_train_all, y_train.loc[:,'win_side'])\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results = results.loc[:, ['param_alpha', 'param_learning_rate', 'mean_train_score', 'mean_test_score', 'rank_test_score']]\n",
    "results = results.sort_values('rank_test_score')\n",
    "results #No distinction when varying learning_rate and alpha (strength of the l2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7af8032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/amaribauer/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.157370</td>\n",
       "      <td>11.384977</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.082112</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(100, 50, 25)</td>\n",
       "      <td>constant</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>151.775454</td>\n",
       "      <td>3.714696</td>\n",
       "      <td>0.400708</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>constant</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>60.424816</td>\n",
       "      <td>0.731582</td>\n",
       "      <td>0.446385</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>constant</td>\n",
       "      <td>2000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>149.979677</td>\n",
       "      <td>1.729585</td>\n",
       "      <td>0.385319</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>constant</td>\n",
       "      <td>2000</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>73.757306</td>\n",
       "      <td>0.709461</td>\n",
       "      <td>0.442606</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.653634</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>67.255533</td>\n",
       "      <td>0.453887</td>\n",
       "      <td>0.670809</td>\n",
       "      <td>0.153749</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>75.811057</td>\n",
       "      <td>5.666909</td>\n",
       "      <td>0.624910</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>90.136587</td>\n",
       "      <td>0.359310</td>\n",
       "      <td>0.613940</td>\n",
       "      <td>0.123514</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>constant</td>\n",
       "      <td>2000</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>75.738773</td>\n",
       "      <td>2.176713</td>\n",
       "      <td>0.774358</td>\n",
       "      <td>0.134335</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>constant</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61.200401</td>\n",
       "      <td>3.155786</td>\n",
       "      <td>0.505273</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 40, 25)</td>\n",
       "      <td>constant</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543933</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        29.157370     11.384977         0.571429        0.082112   \n",
       "159     151.775454      3.714696         0.400708        0.014876   \n",
       "160      60.424816      0.731582         0.446385        0.030189   \n",
       "161     149.979677      1.729585         0.385319        0.053872   \n",
       "162      73.757306      0.709461         0.442606        0.014357   \n",
       "..             ...           ...              ...             ...   \n",
       "69       67.255533      0.453887         0.670809        0.153749   \n",
       "67       75.811057      5.666909         0.624910        0.075865   \n",
       "65       90.136587      0.359310         0.613940        0.123514   \n",
       "63       75.738773      2.176713         0.774358        0.134335   \n",
       "61       61.200401      3.155786         0.505273        0.028443   \n",
       "\n",
       "    param_activation param_alpha param_hidden_layer_sizes param_learning_rate  \\\n",
       "0               tanh      0.0001            (100, 50, 25)            constant   \n",
       "159             relu      0.0001                (4, 3, 2)            constant   \n",
       "160             relu      0.0001                (4, 3, 2)            constant   \n",
       "161             relu      0.0001                (4, 3, 2)            constant   \n",
       "162             relu      0.0001                (4, 3, 2)            adaptive   \n",
       "..               ...         ...                      ...                 ...   \n",
       "69              tanh        0.01             (50, 40, 25)            adaptive   \n",
       "67              tanh        0.01             (50, 40, 25)            adaptive   \n",
       "65              tanh        0.01             (50, 40, 25)            constant   \n",
       "63              tanh        0.01             (50, 40, 25)            constant   \n",
       "61              tanh        0.01             (50, 40, 25)            constant   \n",
       "\n",
       "    param_max_iter param_solver  ... split1_test_score  split2_test_score  \\\n",
       "0              500          sgd  ...          0.652720           0.655462   \n",
       "159           1000         adam  ...          0.652720           0.655462   \n",
       "160           2000          sgd  ...          0.652720           0.655462   \n",
       "161           2000         adam  ...          0.652720           0.655462   \n",
       "162            500          sgd  ...          0.652720           0.655462   \n",
       "..             ...          ...  ...               ...                ...   \n",
       "69            1000         adam  ...          0.543933           0.621849   \n",
       "67             500         adam  ...          0.543933           0.621849   \n",
       "65            2000         adam  ...          0.543933           0.621849   \n",
       "63            1000         adam  ...          0.543933           0.621849   \n",
       "61             500         adam  ...          0.543933           0.621849   \n",
       "\n",
       "     mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0           0.653634        0.001293                1            0.654088   \n",
       "159         0.653634        0.001293                1            0.654088   \n",
       "160         0.653634        0.001293                1            0.654088   \n",
       "161         0.653634        0.001293                1            0.654088   \n",
       "162         0.653634        0.001293                1            0.654088   \n",
       "..               ...             ...              ...                 ...   \n",
       "69          0.592220        0.034437              283            1.000000   \n",
       "67          0.592220        0.034437              283            1.000000   \n",
       "65          0.592220        0.034437              283            1.000000   \n",
       "63          0.592220        0.034437              283            1.000000   \n",
       "61          0.592220        0.034437              283            1.000000   \n",
       "\n",
       "     split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.654088             0.65272          0.653632         0.000645  \n",
       "159            0.654088             0.65272          0.653632         0.000645  \n",
       "160            0.654088             0.65272          0.653632         0.000645  \n",
       "161            0.654088             0.65272          0.653632         0.000645  \n",
       "162            0.654088             0.65272          0.653632         0.000645  \n",
       "..                  ...                 ...               ...              ...  \n",
       "69             1.000000             1.00000          1.000000         0.000000  \n",
       "67             1.000000             1.00000          1.000000         0.000000  \n",
       "65             1.000000             1.00000          1.000000         0.000000  \n",
       "63             1.000000             1.00000          1.000000         0.000000  \n",
       "61             1.000000             1.00000          1.000000         0.000000  \n",
       "\n",
       "[288 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state = 0) \n",
    "#test across all parameter spaces. This will take a few hours.\n",
    "param_space = {'max_iter' : [500, 1000, 2000],\n",
    "               'alpha': [0.0001, 0.01, 0.05, 0.1],\n",
    "               'learning_rate': ['constant','adaptive'],\n",
    "               'hidden_layer_sizes': [(100,50,25),(4,3,2), (50,40,25)],\n",
    "              'activation' : ['tanh', 'relu'],\n",
    "               'solver': ['sgd', 'adam']\n",
    "               }\n",
    "search = GridSearchCV(mlp, param_space, n_jobs=-1, cv=3, return_train_score=True)\n",
    "search.fit(X_train_all, y_train.loc[:,'win_side'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results = results.sort_values('rank_test_score')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0a20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352ed63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e10870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.6514657980456026\n",
      "f1_score: 0.7889546351084813\n"
     ]
    }
   ],
   "source": [
    "#top model with simplest parameters\n",
    "#162,relu,0.0001,\"(4, 3, 2)\",adaptive,500,sgd,\"{'activation': 'relu', 'alpha': 0.0001, \n",
    "#'hidden_layer_sizes': (4, 3, 2), 'learning_rate': 'adaptive', 'max_iter': 500, 'solver': 'sgd'}\"\n",
    "mlp = MLPClassifier(random_state = 0, max_iter = 500, solver = 'sgd', \n",
    "                    hidden_layer_sizes = (4,3,2), learning_rate = 'adaptive',\n",
    "                   activation='relu', alpha = 0.0001)\n",
    "mlp.fit(X_train_all,y_train.loc[:,'win_side'])\n",
    "predict_test = mlp.predict(X_test_all)\n",
    "print('accuracy_score:',accuracy_score(y_test.loc[:,'win_side'],predict_test))\n",
    "print('f1_score:', f1_score(y_test.loc[:,'win_side'],predict_test))\n",
    "#default alpha and activation are fine, rest were tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ebeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat = X_train_all.loc[:,['convo_count',\n",
    "       'justice_utt_share', 'petitioner_advocate_utt_share', 'cons_just','prop_cons']]\n",
    "X_test_feat = X_test_all.loc[:,['convo_count',\n",
    "       'justice_utt_share', 'petitioner_advocate_utt_share', 'cons_just','prop_cons']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc50c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes All\n",
      "accuracy_score: 0.6482084690553745\n",
      "f1_score: 0.7768595041322315\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB() \n",
    "model.fit(X_train_all,y_train.loc[:,'win_side'])\n",
    "win_pred = model.predict(X_test_all)\n",
    "\n",
    "print('Naive Bayes All')\n",
    "print('accuracy_score:', accuracy_score(y_test.loc[:,'win_side'],win_pred))\n",
    "print('f1_score:', f1_score(y_test.loc[:,'win_side'],win_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899d357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes All\n",
      "accuracy_score: 0.6514657980456026\n",
      "f1_score: 0.7820773930753564\n"
     ]
    }
   ],
   "source": [
    "model_feat = GaussianNB() \n",
    "model_feat.fit(X_train_feat,y_train.loc[:,'win_side'])\n",
    "win_pred = model_feat.predict(X_test_feat)\n",
    "\n",
    "print('Naive Bayes All')\n",
    "print('accuracy_score:', accuracy_score(y_test.loc[:,'win_side'],win_pred))\n",
    "print('f1_score:', f1_score(y_test.loc[:,'win_side'],win_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f918e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = X_train_all.loc[:,X_train_all.columns.difference(['convo_count',\n",
    "       'justice_utt_share', 'petitioner_advocate_utt_share', 'cons_just','prop_cons'])]\n",
    "X_test_tfidf = X_test_all.loc[:,X_test_all.columns.difference(['convo_count',\n",
    "       'justice_utt_share', 'petitioner_advocate_utt_share', 'cons_just','prop_cons'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c30eb0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abbott</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoning</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019_19-67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013_12-1315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005_04-1186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006_05-6551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005_05-5224</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016_16-6219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007_06-984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013_12-79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_11-982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014_13-628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows Ã— 13831 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aaa       aba   abandon  abandoned  abandoning  abandonment  \\\n",
       "id                                                                          \n",
       "2019_19-67    0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "2013_12-1315  0.0  0.000000  0.000000   0.000000    0.000000     0.020612   \n",
       "2005_04-1186  0.0  0.008259  0.000000   0.000000    0.000000     0.000000   \n",
       "2006_05-6551  0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "2005_05-5224  0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "...           ...       ...       ...        ...         ...          ...   \n",
       "2016_16-6219  0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "2007_06-984   0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "2013_12-79    0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "2012_11-982   0.0  0.000000  0.005297   0.010163    0.007013     0.014189   \n",
       "2014_13-628   0.0  0.000000  0.000000   0.000000    0.000000     0.000000   \n",
       "\n",
       "              abandons  abate  abated  abbott  ...  younger  youth  youthful  \\\n",
       "id                                             ...                             \n",
       "2019_19-67         0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2013_12-1315       0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2005_04-1186       0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2006_05-6551       0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2005_05-5224       0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "...                ...    ...     ...     ...  ...      ...    ...       ...   \n",
       "2016_16-6219       0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2007_06-984        0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2013_12-79         0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2012_11-982        0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "2014_13-628        0.0    0.0     0.0     0.0  ...      0.0    0.0       0.0   \n",
       "\n",
       "              zenith      zero  zillion  zip  zone  zones  zoning  \n",
       "id                                                                 \n",
       "2019_19-67       0.0  0.023168      0.0  0.0   0.0    0.0     0.0  \n",
       "2013_12-1315     0.0  0.000000      0.0  0.0   0.0    0.0     0.0  \n",
       "2005_04-1186     0.0  0.000000      0.0  0.0   0.0    0.0     0.0  \n",
       "2006_05-6551     0.0  0.014269      0.0  0.0   0.0    0.0     0.0  \n",
       "2005_05-5224     0.0  0.005559      0.0  0.0   0.0    0.0     0.0  \n",
       "...              ...       ...      ...  ...   ...    ...     ...  \n",
       "2016_16-6219     0.0  0.000000      0.0  0.0   0.0    0.0     0.0  \n",
       "2007_06-984      0.0  0.003443      0.0  0.0   0.0    0.0     0.0  \n",
       "2013_12-79       0.0  0.003724      0.0  0.0   0.0    0.0     0.0  \n",
       "2012_11-982      0.0  0.000000      0.0  0.0   0.0    0.0     0.0  \n",
       "2014_13-628      0.0  0.000000      0.0  0.0   0.0    0.0     0.0  \n",
       "\n",
       "[716 rows x 13831 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2613301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes All\n",
      "accuracy_score: 0.6482084690553745\n",
      "f1_score: 0.7768595041322315\n"
     ]
    }
   ],
   "source": [
    "model_tfidf = GaussianNB() \n",
    "model_tfidf.fit(X_train_tfidf,y_train.loc[:,'win_side'])\n",
    "win_pred = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print('Naive Bayes All')\n",
    "print('accuracy_score:', accuracy_score(y_test.loc[:,'win_side'],win_pred))\n",
    "print('f1_score:', f1_score(y_test.loc[:,'win_side'],win_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
